{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "### By **[NimbleBox](https://www.nimblebox.ai)**\n",
    "\n",
    "\n",
    "[<img src=\"./assets/nbx.jpeg\" alt=\"NimbleBox.ai logo\" width=\"600\"/>](https://www.nimblebox.ai)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What will we learn\n",
    " \n",
    "We are going to understand about Backward Propagation and gradient descent both of which are used to find the parameters we talked about in the previous notebooks which were the **weight** and **bias** parameters which we used in the forward propagation to compute the output of the Neural networks.\n",
    " \n",
    "Also in the previous notebooks we just assumed some weight and bias parameters but when training Neural networks it is a general practice to randomly initialize the weight and bias parameters and then use gradient descent to find the best parameters from there.\n",
    " \n",
    "So let's dive right in and see what both of these things are.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Propagation \n",
    " \n",
    "Backward Propagation is the step where we march backwards in a Neural Network calculating the gradients or in simple terms calculating some derivatives. Now let me explain the meaning of this line.\n",
    " \n",
    "We will be using our simple neural network from the previous notebook but going backward this time.\n",
    " \n",
    "<img src=\"./assets/back_prop.png\" width=\"700\"/>\n",
    " \n",
    "We are going to back propagate the errors to the actual weights that produced them, if you remember from the previous notebook we used $ W_1, b_1, W_2 $ and $ b_2 $ to compute the result and then used a loss function which told us about the error.\n",
    " \n",
    "So our goal is to calculate the gradient of the error with respect to the parameters we used so the actual terms we want to calculate are $ ∂E/∂W_1, ∂E/∂b_1, ∂E/∂W_2 $ and $ ∂E/∂b_2 $ where E is the error or the loss function that we used. \n",
    " \n",
    "To calculate the gradients with respect to the parameters so we can update them happens through chain rule, so let's calculate  $ ∂E/∂W_1 $ in depth and then you can easily calculate the other gradients easily \n",
    " \n",
    "But before that let's see what we actually have to calculate for that let's see what you did in the forward propagation in a single equation, I will be using $ E $ here to show the error calculated by the loss function. \n",
    " \n",
    "$$ E = (1/2n) * Σ((Y - (W_2 * sigmoid(W_1 * X + b_1) + b_2))^2)$$ \n",
    " \n",
    "where sigmoid function was.\n",
    " \n",
    "<img src=\"./assets/sigmoid.png\" width=150/>\n",
    " \n",
    "Wow our small calculation turned out to be pretty big at the end and that's is why we don't calculate the derivative of this equation as a whole and use chain rule to calculate the derivatives with respect to the previous step until we reach to our parameter $ W_1 $ with whom we want to calculate the gradient with. And I would like to mention that when I say derivative I mostly mean **partial derivative** with respect to the parameter we are trying to update, because updating that parameter with the changes that happened because of other parameters doesn't make sense and won't be beneficial.\n",
    " \n",
    "$$ ∂E/∂W_1 = ∂E/∂Y\\_hat * ∂Y\\_hat/∂A * ∂A/∂Z * ∂Z/∂W_1 $$\n",
    " \n",
    "So now we have to calculate these derivatives to get what we want, this may look like a lot but don't worry the derivatives are really easy to understand.\n",
    " \n",
    "1. $ ∂E/∂Y\\_hat = (1/n) * Σ(Y-Y\\_hat) $\n",
    "2. $ ∂Y\\_hat/∂A = W_2 $\n",
    "3. $ ∂A/∂Z = A*(1 - A) $\n",
    "4. $ ∂Z/∂W_1 = X $\n",
    " \n",
    "The derivative of the sigmoid(Activation function) is a bit involved and if you want to know how we reached to that there is a great [resource](http://www.ai.mit.edu/courses/6.892/lecture8-html/sld015.htm) by MIT.\n",
    " \n",
    "So finally done all that let's put all of them back and take a good look.\n",
    " \n",
    "$$ ∂E/∂W_1 = (1/n) * Σ(Y-Y\\_hat) * W_2 * A*(1 - A) * X $$\n",
    " \n",
    "With this we know how to calculate the gradients with respect to the parameters and propagate the error back to our parameters so we can get better predictions, but wait we haven't updated the actual parameters yet which were $ W_1, b_1, W_2 $ and $ b_2 $ to the rescue comes gradient descent. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    " \n",
    "I think most of you have heard about minima and as we know that there are a lot of ways to find the minima of a function and we know that essentially our loss function that tells us about the prediction error of our neural network is a function. But why would we want to find the minima of our loss function and that is to reduce the error of our Neural network and increase the accuracy.\n",
    " \n",
    "Gradient descent achieves this through an iterative process in which it updates the parameters of the neural network to reach to the minima or a local minima of a loss function and thus reduce the error. \n",
    " \n",
    "Now let's see how gradient descent updates the parameters of the neural network.\n",
    " \n",
    "$$ W_1 = W_1 - α * ∂E/∂W_1 $$\n",
    " \n",
    "A similar equation is used to update the other parameters.\n",
    " \n",
    "$$ b_1 = b_1 - α * ∂E/∂b_1 $$\n",
    "$$ W_2 = W_2 - α * ∂E/∂W_2 $$\n",
    "$$ b_2 = b_2 - α * ∂E/∂b_2 $$\n",
    " \n",
    "It uses the gradients that we calculated in our back propagation step and uses them to update the actual parameter. now let's talk about what is the new parameter which is $ α $ or formally called the **learning rate**. It controls how big steps the gradient descent will take each time it updates the parameters.\n",
    " \n",
    "If we assume that we just had a single parameter and we plot it with respect to the loss function we will get a plot like this.\n",
    " \n",
    "<img src=\"./assets/gradient_descent.png\" width=700/>\n",
    " \n",
    "Each arrow shows an iteration of gradient descent to achieve the minima and the length of the arrows is controlled by the learning rate.\n",
    " \n",
    "Choosing a good value of learning rate is a highly iterative process if you are trying to do it yourself and the convergence of your neural network depends highly on the learning rate. By convergence I mean that is gradient descent able to achieve a minima or not because as you see in the parameter update equations $ α $ is multiplied by the gradients and thus decides the step size.\n",
    " \n",
    "To visualize what this means let's again take our above plot and see what will happen if we take a value of $ α $ that is too large.\n",
    " \n",
    "<img src=\"./assets/lr_big_plot.png\" width=700/>\n",
    " \n",
    "I might have drawn the arrows a bit too big or dramatic but it conveys the meaning so as you can see in the above diagram because of $ α $ being too large it never achieves a minima and fails to converge.\n",
    " \n",
    "Now let's see the case where $ α $ is small.\n",
    " \n",
    "<img src=\"./assets/lr_small_plot.png\" width=700/>\n",
    " \n",
    "As we can see that as the value of learning rate is small the arrows are small and gradient descent is slowly marching towards some parameters that will achieve a minima on the loss function but these steps are so small that it may take forever to converge to such a good minima and it is possible that with such small steps it might even get stuck in a local minima rather than getting to a global minima.\n",
    " \n",
    "So choosing an appropriate value of learning rate($ α $) is something that should be done carefully to train a good model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next \n",
    "\n",
    "Now armed with the knowledge of forward propagation, backward propagation and gradient descent let's see some rough steps of how a neural network is trained, don't worry the next notebook will contain an implementation of a neural network with each of these steps in more detail.\n",
    " \n",
    "1. Forward Propagation (Compute the loss).\n",
    "2. Backward propagation (Compute the gradients).\n",
    "3. Gradient descent (Update the parameters). \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
